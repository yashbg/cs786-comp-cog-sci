{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "\n",
    "\\- Yash Gupta (190997)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-barbados",
   "metadata": {},
   "source": [
    "### Part 1: 25 marks\n",
    "\n",
    "Fill in the partially complete lines of code in the file temporal_context_model_empty.m to make a temporal context model of memory retrieval that retrieves about 7 items from an encoded list efficiently.\n",
    "\n",
    "This should not be very challenging if you've followed the concept of the TCM in class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The temporal context model assumes that the past becomes increasingly dissimilar to the future, so that memories become harder to retrieve the farther away in the past they are. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to model the world as a set of N continuous-valued features. We will model observations of states of the world as samples from N Gaussians with time-varying means and fixed variance. For simplicity, we will assume that agents change nothing in the world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import random as rand\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_from_a_dist(p):\n",
    "    if np.sum(p) == 0:\n",
    "        p = 0.05 * np.ones(len(p))\n",
    "    p /= np.sum(p)\n",
    "    idx = np.where(rand.random(1) - np.cumsum(p) < 0)\n",
    "    sample = np.min(idx)\n",
    "    out = np.zeros(len(p))\n",
    "    out[sample] = 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_WORLD_FEATURES = 5\n",
    "N_ITEMS = 10\n",
    "ENCODING_TIME = 500\n",
    "TEST_TIME = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will fix the presentation schedule; We'll assuming its random. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule = np.column_stack((np.sort(np.round(rand.random(N_ITEMS) * ENCODING_TIME)), np.arange(N_ITEMS)))\n",
    "schedule_load = ENCODING_TIME / np.median(np.diff(schedule[:, 0])) # variable important for parts 2,3 of assignment\n",
    "encoding = np.zeros((N_ITEMS, N_WORLD_FEATURES + 1))\n",
    "\n",
    "world_m = np.array([1, 2, 1, 2, 3], dtype=float)\n",
    "world_var = 1\n",
    "delta = 0.05\n",
    "beta_param = 0.001\n",
    "m = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulating encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "for time in range(ENCODING_TIME):\n",
    "    world_m += delta\n",
    "    world = rand.normal(world_m, world_var)\n",
    "    # any item I want to encode in memory, I encode in association with the\n",
    "    # state of the world at that time.\n",
    "    if m < N_ITEMS:\n",
    "        if time == schedule[m, 0]:\n",
    "            encoding[m, :] = np.append(world, m) # encode into the encoding vector\n",
    "            m += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulating retrieval using SAM, but with a bijective image-item mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.zeros(TEST_TIME)\n",
    "while time < ENCODING_TIME + TEST_TIME:\n",
    "    # the state of the world is the retrieval cue\n",
    "    world_m += delta\n",
    "    world = rand.normal(world_m, world_var) # model world evolution\n",
    "    soa = np.zeros(N_ITEMS)\n",
    "    for m in range(N_ITEMS):\n",
    "        soa[m] = np.dot(encoding[m], np.append(world, m)) # finding association strengths\n",
    "    soa /= np.linalg.norm(soa) # normalize\n",
    "    out[time - ENCODING_TIME] = np.where(draw_from_a_dist(soa) > 0)[0]\n",
    "    time += 1\n",
    "\n",
    "success = len(np.unique(out)) # success is number of unique retrievals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Humans can retrieve about 7 items effectively from memory. We want this model to behave like humans. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the average success over 100 iterations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average success over 100 iterations: 7.76\n"
     ]
    }
   ],
   "source": [
    "success_sum = 0\n",
    "num_iter = 100\n",
    "\n",
    "for i in range(num_iter):\n",
    "    schedule = np.column_stack((np.sort(np.round(rand.random(N_ITEMS) * ENCODING_TIME)), np.arange(N_ITEMS)))\n",
    "    schedule_load = ENCODING_TIME / np.median(np.diff(schedule[:, 0]))\n",
    "    encoding = np.zeros((N_ITEMS, N_WORLD_FEATURES + 1))\n",
    "\n",
    "    world_m = np.array([1, 2, 1, 2, 3], dtype=float)\n",
    "    world_var = 1\n",
    "    delta = 0.05\n",
    "    beta_param = 0.001\n",
    "    m = 0\n",
    "\n",
    "    for time in range(ENCODING_TIME):\n",
    "        world_m += delta\n",
    "        world = rand.normal(world_m, world_var)\n",
    "        if m < N_ITEMS:\n",
    "            if time == schedule[m, 0]:\n",
    "                encoding[m, :] = np.append(world, m)\n",
    "                m += 1\n",
    "\n",
    "    out = np.zeros(TEST_TIME)\n",
    "    while time < ENCODING_TIME + TEST_TIME:\n",
    "        world_m += delta\n",
    "        world = rand.normal(world_m, world_var)\n",
    "        soa = np.zeros(N_ITEMS)\n",
    "        for m in range(N_ITEMS):\n",
    "            soa[m] = np.dot(encoding[m], np.append(world, m))\n",
    "        soa /= np.linalg.norm(soa)\n",
    "        out[time - ENCODING_TIME] = np.where(draw_from_a_dist(soa) > 0)[0]\n",
    "        time += 1\n",
    "\n",
    "    success = len(np.unique(out))\n",
    "    success_sum += success\n",
    "\n",
    "avg_success = success_sum / num_iter\n",
    "print(f'Average success over {num_iter} iterations: {avg_success}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, our model behaves like humans as it retrieves more than 7 items from an encoded list efficiently, on average. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-barbados",
   "metadata": {},
   "source": [
    "### Part 2: 25 marks\n",
    "\n",
    "Alongside the TCM you have implemented, you have also implemented assumptions about the physics of the world. Namely, you have assumed that the world can be represented as a set of draws from N independent Gaussians, and that the means of these Gaussians evolve over time linearly. Now we change this. We assume that the world contains context changes, and represent this fact by sampling the rate of drift over time (delta) in the feature means itself from a mixture of two Gaussians, one with a small mean to denote small changes, and one with a large mean to denote large changes. \n",
    "\n",
    "Implement this new physics of the world in the model, and design an encoding schedule that lets your model retrieve effectively (>7 success). The trivial solution is to shove all the encodings towards the back end of the encoding period, but doing so will increase your encoding load (proxy for study effort). \n",
    "\n",
    "An optimal solution would find the scheduling pattern that minimizes % encoding load while maintaining average retrieval success across multiple runs at 7. See if you can find it, assuming your retrieving agent knows the parameters of the model that will generate his world contexts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a function that generates a bimodal gaussian distribution with the given means. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `beta_param` is the mixing proportions of the two gaussians. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bimodal_gaussian(mean1, mean2, var, beta_param):\n",
    "    n = 10000\n",
    "    x1 = rand.normal(mean1, var, int(n * beta_param))\n",
    "    x2 = rand.normal(mean2, var, int(n * (1 - beta_param)))\n",
    "    x = np.concatenate((x1, x2))\n",
    "    plt.hist(x, bins=100)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean1 = 0.01\n",
    "mean2 = 1\n",
    "var = 0.25\n",
    "beta_param = 0.25\n",
    "bimodal_gaussian_dist = bimodal_gaussian(mean1, mean2, var, beta_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use this distribution to sample the deltas and design an encoding schedule that lets your model retrieve effectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trivial solution is to shove all the encodings towards the back end of the encoding period. Let's try it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tcm(schedule):\n",
    "    success_sum = 0\n",
    "    load_sum = 0\n",
    "    num_iter = 100\n",
    "\n",
    "    for i in range(num_iter):\n",
    "        schedule_load = ENCODING_TIME / np.median(np.diff(schedule[:, 0]))\n",
    "        encoding = np.zeros((N_ITEMS, N_WORLD_FEATURES + 1))\n",
    "\n",
    "        world_m = np.array([1, 2, 1, 2, 3], dtype=float)\n",
    "        world_var = 1\n",
    "        m = 0\n",
    "\n",
    "        for time in range(ENCODING_TIME):\n",
    "            delta = rand.choice(bimodal_gaussian_dist)\n",
    "            world_m += delta\n",
    "            world = rand.normal(world_m, world_var)\n",
    "            if m < N_ITEMS:\n",
    "                if time == schedule[m, 0]:\n",
    "                    encoding[m, :] = np.append(world, m)\n",
    "                    m += 1\n",
    "\n",
    "        out = np.zeros(TEST_TIME)\n",
    "        while time < ENCODING_TIME + TEST_TIME:\n",
    "            delta = rand.choice(bimodal_gaussian_dist)\n",
    "            world_m += delta\n",
    "            world = rand.normal(world_m, world_var)\n",
    "            soa = np.zeros(N_ITEMS)\n",
    "            for m in range(N_ITEMS):\n",
    "                soa[m] = np.dot(encoding[m], np.append(world, m))\n",
    "            soa /= np.linalg.norm(soa)\n",
    "            out[time - ENCODING_TIME] = np.where(draw_from_a_dist(soa) > 0)[0]\n",
    "            time += 1\n",
    "\n",
    "        success = len(np.unique(out))\n",
    "        success_sum += success\n",
    "        load_sum += schedule_load\n",
    "\n",
    "    avg_success = success_sum / num_iter\n",
    "    avg_load = load_sum / num_iter\n",
    "    print(f'Average success over {num_iter} iterations: {avg_success}')\n",
    "    print(f'Average schedule load over {num_iter} iterations: {avg_load}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average success over 100 iterations: 9.01\n",
      "Average schedule load over 100 iterations: 500.0\n"
     ]
    }
   ],
   "source": [
    "schedule = np.column_stack((np.sort(np.arange(490, 500)), np.arange(N_ITEMS)))\n",
    "tcm(schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, our model is able to retrieve effectively even when the world contains context changes by shoving all the encodings towards the back end of the encoding period. But this increased the schedule load. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try to reduce the schedule load while keeping the success above 7. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this, we will try to maximize the median of the intervals. To this this, we will shove the first 5 encodings towards the back and put the rest of the encodings with equal spaces before the first 5 encodings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average success over 100 iterations: 7.66\n",
      "Average schedule load over 100 iterations: 5.050505050505038\n"
     ]
    }
   ],
   "source": [
    "l = [0, 99, 198, 297, 396, 495, 496, 497, 498, 499]\n",
    "schedule = np.column_stack((l, np.arange(N_ITEMS)))\n",
    "tcm(schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our model is able to retrieve effectively with minimum schedule load. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: 50 marks\n",
    "\n",
    "Do the same thing, but this time assuming that the retrieving agent does not know the parameters of the world generating model, just the fact that the rate of drift is sampled from a bimodal distribution. Hint: you'll have to have the agent learn the drift distribution parameters. EM is your friend here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the EM algorithm to learn the parameters of the bimodal distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's first try shoving all the encodings towards the back end of the encoding period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tcm_em(schedule):\n",
    "    success_sum = 0\n",
    "    load_sum = 0\n",
    "    num_iter = 100\n",
    "    deltas = []\n",
    "\n",
    "    for i in range(num_iter):\n",
    "        schedule_load = ENCODING_TIME / np.median(np.diff(schedule[:, 0]))\n",
    "        encoding = np.zeros((N_ITEMS, N_WORLD_FEATURES + 1))\n",
    "\n",
    "        world_m = np.array([1, 2, 1, 2, 3], dtype=float)\n",
    "        world_var = 1\n",
    "        m = 0\n",
    "\n",
    "        for time in range(ENCODING_TIME):\n",
    "            delta = rand.choice(bimodal_gaussian_dist)\n",
    "            deltas.append([delta])\n",
    "            world_m += delta\n",
    "            world = rand.normal(world_m, world_var)\n",
    "            if m < N_ITEMS:\n",
    "                if time == schedule[m, 0]:\n",
    "                    encoding[m, :] = np.append(world, m)\n",
    "                    m += 1\n",
    "        \n",
    "        # Use the EM algorithm to learn the parameters of the bimodal distribution\n",
    "        gm = GaussianMixture(n_components=2, random_state=0).fit(deltas)\n",
    "\n",
    "        out = np.zeros(TEST_TIME)\n",
    "        while time < ENCODING_TIME + TEST_TIME:\n",
    "            delta = gm.sample()[0][0][0]\n",
    "            world_m += delta\n",
    "            world = rand.normal(world_m, world_var)\n",
    "            soa = np.zeros(N_ITEMS)\n",
    "            for m in range(N_ITEMS):\n",
    "                soa[m] = np.dot(encoding[m], np.append(world, m))\n",
    "            soa /= np.linalg.norm(soa)\n",
    "            out[time - ENCODING_TIME] = np.where(draw_from_a_dist(soa) > 0)[0]\n",
    "            time += 1\n",
    "\n",
    "        success = len(np.unique(out))\n",
    "        success_sum += success\n",
    "        load_sum += schedule_load\n",
    "\n",
    "    avg_success = success_sum / num_iter\n",
    "    avg_load = load_sum / num_iter\n",
    "    print(f'Average success over {num_iter} iterations: {avg_success}')\n",
    "    print(f'Average schedule load over {num_iter} iterations: {avg_load}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average success over 100 iterations: 8.74\n",
      "Average schedule load over 100 iterations: 500.0\n"
     ]
    }
   ],
   "source": [
    "schedule = np.column_stack((np.sort(np.arange(490, 500)), np.arange(N_ITEMS)))\n",
    "tcm_em(schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, our model is able to retrieve effectively even when the retrieving agent does not know the parameters of the world generating model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try to reduce the schedule load while keeping the success above 7 by using the optimal scheduling as described before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average success over 100 iterations: 7.74\n",
      "Average schedule load over 100 iterations: 5.050505050505038\n"
     ]
    }
   ],
   "source": [
    "l = [0, 99, 198, 297, 396, 495, 496, 497, 498, 499]\n",
    "schedule = np.column_stack((l, np.arange(N_ITEMS)))\n",
    "tcm_em(schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our model is able to retrieve effectively with minimum schedule load. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "27f98c3cd29bdbbbcf21e34becd61d5d6f13f7e1fe4b4cefd3f8a1ca844857c7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('cocosci')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
