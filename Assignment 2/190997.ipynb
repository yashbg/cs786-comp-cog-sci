{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59e7c7b8",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\\- Yash Gupta (190997)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-barbados",
   "metadata": {},
   "source": [
    "### Q1. \n",
    "Gabor filters are renowned for their functional equivalence to simple orientation-specific cells in primary visual cortex. I want you to design complex cells that can recognize  \n",
    "(a) triangles and  \n",
    "(b) squares  \n",
    "using a bank of orientation-selective 2D Gabor filters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the base of the triangle and the square be horizontal and the triangle be an isosceles right-angled triangle with the top angle as the right angle. We can design complex cells for them without loss of generality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_corners(img):\n",
    "    corners = []\n",
    "    _, contours, _ =  cv2.findContours(img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for i in range(len(contours)):\n",
    "        corners.append(np.mean(contours[i].reshape(-1, 2), axis=0))\n",
    "    return corners\n",
    "\n",
    "def triangle_filter(img, sigma):\n",
    "    kernel = np.ones((5, 5), dtype=np.uint8)\n",
    "\n",
    "    gabor_left = cv2.getGaborKernel((31, 31), sigma, np.pi / 4, 2, 0.5, 0, ktype=cv2.CV_32F)\n",
    "    img_left = cv2.filter2D(img, cv2.CV_8UC3, gabor_left)\n",
    "    img_left = cv2.dilate(img_left, kernel, iterations=2)\n",
    "    img_left = cv2.erode(img_left, kernel, iterations=2)\n",
    "    blur = cv2.GaussianBlur(img_left, (5, 5), 0)\n",
    "    _, dst_left = cv2.threshold(blur, 180, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    gabor_right = cv2.getGaborKernel((31, 31), sigma, 3 * np.pi / 4, 2, 0.5, 0, ktype=cv2.CV_32F)\n",
    "    img_right = cv2.filter2D(img, cv2.CV_8UC3, gabor_right)\n",
    "    img_right = cv2.dilate(img_right, kernel, iterations=2)\n",
    "    img_right = cv2.erode(img_right, kernel, iterations=2)\n",
    "    blur = cv2.GaussianBlur(img_right, (5, 5), 0)\n",
    "    _, dst_right = cv2.threshold(blur, 180, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    gabor_base = cv2.getGaborKernel((31, 31), sigma, np.pi / 2, 2, 0.5, 0, ktype=cv2.CV_32F)\n",
    "    img_base = cv2.filter2D(img, cv2.CV_8UC3, gabor_base)\n",
    "    img_base = cv2.dilate(img_base, kernel, iterations=2)\n",
    "    img_base = cv2.erode(img_base, kernel, iterations=2)\n",
    "    blur = cv2.GaussianBlur(img_base, (5, 5), 0)\n",
    "    _, dst_base = cv2.threshold(blur, 180, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    corner_left = np.uint8(dst_right * dst_base) * 255\n",
    "    corner_right = np.uint8(dst_left * dst_base) * 255\n",
    "    corner_top = np.uint8(dst_left * dst_right) * 255\n",
    "\n",
    "    return [corner_left, corner_right, corner_top]\n",
    "\n",
    "def square_filter(img, sigma):\n",
    "    kernel = np.ones((5, 5), dtype=np.uint8)\n",
    "\n",
    "    gabor_horizontal = cv2.getGaborKernel((31, 31), sigma, 0, 2, 0.5, 0, ktype=cv2.CV_32F)\n",
    "    img_horizontal = cv2.filter2D(img, cv2.CV_8UC3, gabor_horizontal)\n",
    "    img_horizontal = cv2.dilate(img_horizontal, kernel, iterations=2)\n",
    "    img_horizontal = cv2.erode(img_horizontal, kernel, iterations=2)\n",
    "    blur = cv2.GaussianBlur(img_horizontal, (5, 5), 0)\n",
    "    _, dst_horizontal = cv2.threshold(blur, 180, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    gabor_vertical = cv2.getGaborKernel((31, 31), sigma, np.pi / 2, 2, 0.5, 0, ktype=cv2.CV_32F)\n",
    "    img_vertical = cv2.filter2D(img, cv2.CV_8UC3, gabor_vertical)\n",
    "    img_vertical = cv2.dilate(img_vertical, kernel, iterations=2)\n",
    "    img_vertical = cv2.erode(img_vertical, kernel, iterations=2)\n",
    "    blur = cv2.GaussianBlur(img_vertical, (5, 5), 0)\n",
    "    _, dst_vertical = cv2.threshold(blur, 180, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    corners = np.uint8(dst_horizontal * dst_vertical) * 255\n",
    "    return corners"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-barbados",
   "metadata": {},
   "source": [
    "### Q2. \n",
    "Once you have complex cells identifying triangles and squares, I want you to simulate the visual search paradigm of Triesman (1980), where the task is to find the odd stimulus in a set of objects. In our case, the objects will be red or blue in color and triangles or squares in shape. Simulating the paradigm means   being   able   to   enter   the   number   of   objects   and   experiment   type (feature/conjunction) as parameters and obtain image frames containing objects with these features as output. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-barbados",
   "metadata": {},
   "source": [
    "### Q3. \n",
    "Once this paradigm is ready, I want you to implement a simple version of feature integration theory, viz. assume there is a matrix each for color and shape information, and that responses must be delayed until information from   all   relevant   stores   has   been   retrieved.   Can   add   timers   and   delays appropriately to simulate neural processing delays. As output, I want graphs of response time versus number of objects in both feature and conjunction search conditions. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6983f0126dc83c2841f3c31fb171b348a3a6b87b04aee638a6a5243e8ac5f4a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
